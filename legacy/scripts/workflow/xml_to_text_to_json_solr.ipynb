{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML Files to SOLR\n",
    "This script takes the XML files and converts them to TXT and to JSON for SOLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pprint, time, re, unicodedata\n",
    "from xml.etree import ElementTree as ET\n",
    "path = \"/data/cm/data/\"\n",
    "\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zeitschrift_struktur(path, zs_number):\n",
    "    print(\"Zeitschrift:\", zs_number, end=\"\\n\\n\")\n",
    "    for jahrgang in os.listdir(path+zs_number+\"/\"+zs_number+\"/\"):\n",
    "        print(\"Jahrgang:\", end=\" \")\n",
    "        print(jahrgang)\n",
    "        print(\"Hefte:\")\n",
    "        for heft in os.listdir(path+zs_number+\"/\"+zs_number+\"/\"+jahrgang+\"/\"):\n",
    "            print(heft, end=\", \")\n",
    "            seiten = len(os.listdir(path+zs_number+\"/\"+zs_number+\"/\"+jahrgang+\"/\"+heft))\n",
    "            print(seiten, \"Seiten.\")\n",
    "    print()\n",
    "    \n",
    "def xml_to_page(tree):\n",
    "    # input: page parsed xml tree\n",
    "    # output: \n",
    "    # page --> paragraphs --> lines\n",
    "    # [[[line1], [line2]], [[line1], [line2]]] etc.\n",
    "    page = []\n",
    "    line = []\n",
    "    par = []\n",
    "    for node in tree.iter():\n",
    "        if node.tag.endswith('charParams'):\n",
    "            line.append(node.text)\n",
    "\n",
    "        elif node.tag.endswith('line') and line != []:\n",
    "            par.append(line)\n",
    "            line = []\n",
    "        elif node.tag.endswith('par') and par != []:\n",
    "            page.append(par)\n",
    "            par = []\n",
    "    return(page)\n",
    "\n",
    "def page_blocks_to_text(page_blocks):\n",
    "    # input: output of xml_to_page\n",
    "    # output: page as plain text\n",
    "    text_page = \"\"\n",
    "    for par in page_blocks:\n",
    "        text_par = \"\"\n",
    "        for line in par:\n",
    "            # apparently sometimes line happens to be [None], then...\n",
    "            if None in line:\n",
    "                line = [el for el in line if el != None]\n",
    "            \n",
    "            text_line = \"\".join(line).strip()\n",
    "            text_par += \" \"\n",
    "            text_par += text_line\n",
    "        text_page += text_par\n",
    "    text_page = text_page.replace(\"¬ \", \"\").replace(\"- \", \"\").replace(\"= \", \"\").replace(\"^ \", \"\").strip()\n",
    "    text_page = text_page.replace(\" ;\", \";\").replace(\" ?\", \"?\").replace(\"•\", \"\")\n",
    "    text_page = text_page.replace(\"    \", \" \").replace(\"   \", \" \").replace(\"  \", \" \")\n",
    "    \n",
    "    return(text_page)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Unicode-Normalisierung (z.B. zusammengesetzte Zeichen)\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "    # typische OCR-Artefakte entfernen / glätten\n",
    "    replacements = {\n",
    "        \"¬ \": \"\",   # Trennfahne\n",
    "        \"- \": \"\",   # Silbentrennung am Zeilenende\n",
    "        \"= \": \"\",   # OCR-Fehler\n",
    "        \"^ \": \"\",   # OCR-Fehler\n",
    "        \" ;\": \";\",\n",
    "        \" ?\": \"?\",\n",
    "        \"•\": \"\",\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "\n",
    "    # Steuerzeichen entfernen, aber alle Buchstaben/Ziffern/Satzzeichen lassen\n",
    "    cleaned_chars = []\n",
    "    for ch in text:\n",
    "        cat = unicodedata.category(ch)\n",
    "        # 'C*' = Control, Surrogate, Unassigned, Private use\n",
    "        if cat.startswith(\"C\"):\n",
    "            # Standard-Whitespace zu normalem Leerzeichen\n",
    "            if ch in (\"\\n\", \"\\r\", \"\\t\"):\n",
    "                cleaned_chars.append(\" \")\n",
    "            # sonst wegwerfen\n",
    "            continue\n",
    "        cleaned_chars.append(ch)\n",
    "\n",
    "    text = \"\".join(cleaned_chars)\n",
    "\n",
    "    # Whitespace normalisieren\n",
    "    text = WHITESPACE_RE.sub(\" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing now 2710055 2710055 0 0\n",
      "Processing now 9616701 9616701 0 0\n",
      "Processing now 2580773 2580773 0 0\n",
      "Processing now 2895450 2895450 0 1413\n",
      "Processing now 2727810 2727810 0 2270\n",
      "Processing now 3129675 3129675 0 2270\n",
      "Processing now 6492429 6492429 0 2270\n",
      "Processing now 2438141 2438141 0 2270\n",
      "Processing now 2827798 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxml/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mzeitschrift\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mjahrgang\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mheft\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     32\u001b[0m     seite_nr \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxml/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mzeitschrift\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mjahrgang\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mheft\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mindex(seite)\n\u001b[0;32m---> 35\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mET\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxml/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mzeitschrift\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mjahrgang\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mheft\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mseite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     page \u001b[38;5;241m=\u001b[39m xml_to_page(tree)\n\u001b[1;32m     38\u001b[0m     page_text \u001b[38;5;241m=\u001b[39m page_blocks_to_text(page)\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py:1222\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[0;32m-> 1222\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m/usr/lib/python3.10/xml/etree/ElementTree.py:580\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    574\u001b[0m     parser \u001b[38;5;241m=\u001b[39m XMLParser()\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(parser, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parse_whole\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;66;03m# The default XMLParser, when it comes from an accelerator,\u001b[39;00m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;66;03m# can define an internal _parse_whole API for efficiency.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;66;03m# It can be used to parse the whole source without feeding\u001b[39;00m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;66;03m# it with chunks.\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize output dictionary\n",
    "current_page = []\n",
    "notadirectory = []\n",
    "isadirectory = []\n",
    "start = time.time()\n",
    "output = []\n",
    "processed_journals = set()\n",
    "\n",
    "\n",
    "for zeitschrift in os.listdir(path+\"xml/\"):\n",
    "    \n",
    "    print(\"Processing now\", zeitschrift, end=\" \")\n",
    "    seiten = []\n",
    "\n",
    "    if zeitschrift not in processed_journals:\n",
    "\n",
    "        if os.path.isdir(path+\"xml/\"+zeitschrift+\"/\"):\n",
    "            for jahrgang in os.listdir(path+\"xml/\"+zeitschrift+\"/\"):\n",
    "            \n",
    "                try:\n",
    "                    if os.path.isdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"):\n",
    "                \n",
    "                        for heft in os.listdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"):\n",
    "                    \n",
    "                            try:\n",
    "                                if os.path.isdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"+heft+\"/\"):\n",
    "                                    for seite in os.listdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"+heft+\"/\"):\n",
    "                                        current_page.append(seite)\n",
    "                                        \n",
    "                                        try:\n",
    "                                            if os.path.isdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"+heft+\"/\"):\n",
    "                                                seite_nr = os.listdir(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"+heft+\"/\").index(seite)\n",
    "                                                \n",
    "                                                \n",
    "                                                tree = ET.parse(path+\"xml/\"+zeitschrift+\"/\"+jahrgang+\"/\"+heft+\"/\"+seite)\n",
    "                                                page = xml_to_page(tree)\n",
    "                                            \n",
    "                                                page_text = page_blocks_to_text(page)\n",
    "                                                page_text.replace('\"', '‟')\n",
    "                                                \n",
    "                                                #write = open(path+\"output/text/\")\n",
    "                                            \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                        except IsADirectoryError as iade:\n",
    "                                            isadirectory.append(iade)\n",
    "                            except NotADirectoryError as nade:\n",
    "                                notadirectory.append(nade)\n",
    "                except NotADirectoryError as nade:\n",
    "                    notadirectory.append(nade)\n",
    "        print(zeitschrift, len(notadirectory), len(isadirectory))\n",
    "        processed_journals.add(zeitschrift)\n",
    "        \n",
    "running_time = time.time()-start\n",
    "print(\"Done in\", running_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize to json SOLR format (JSONL)\n",
    "solr_lines = []\n",
    "\n",
    "for elem in output:\n",
    "    # ID-String\n",
    "    doc_id = f\"{elem['zeitschrift']}_{elem['jahrgang']}_{elem['heft']}_{elem['seite']}\"\n",
    "\n",
    "    # Solr document\n",
    "    solr_doc = {\n",
    "        \"id\": doc_id,\n",
    "        \"text\": elem[\"text\"]\n",
    "    }\n",
    "\n",
    "    solr_lines.append(json.dumps(solr_doc, ensure_ascii=False))\n",
    "\n",
    "# Save file\n",
    "output_file = path + \"output/solr/solr_data.jsonl\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(\"\\n\".join(solr_lines))\n",
    "\n",
    "print(f\"Gespeichert: {output_file} ({len(solr_lines)} Dokumente)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
