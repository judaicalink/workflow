{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pickle, pprint\n",
    "import spacy\n",
    "path_data = \"/data/cm/\"\n",
    "path = \"/home/rovera/cm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|||"
     ]
    }
   ],
   "source": [
    "processed_journals = [j.split('.')[0] for j in os.listdir(path_data+\"output/nlp_pipeline/word_count/\")]\n",
    "\n",
    "for journal in os.listdir(path_data+\"output/text/\"):\n",
    "    \n",
    "    wf = {}\n",
    "    token_count = 0\n",
    "    word_count = 0\n",
    "    \n",
    "    doc_count = 0\n",
    "    \n",
    "    print(\"|\", end=\"\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(path_data+\"output/text/\"+journal+\"/\"):\n",
    "        \n",
    "        for file in files:\n",
    "            doc_count += 1\n",
    "            text = open(root+\"/\"+file, 'r', encoding=\"utf-8\").read()\n",
    "            \n",
    "            \n",
    "            doc = nlp(text)\n",
    "    \n",
    "            for token in doc:\n",
    "                token_count += 1\n",
    "                if not token.is_stop and not token.is_punct:\n",
    "                    \n",
    "                    word_count += 1\n",
    "                    \n",
    "                    token = str(token)\n",
    "                    if token not in wf.keys():\n",
    "                        wf[token] = 1\n",
    "                    else:\n",
    "                        wf[token] += 1\n",
    "    \n",
    "    journal_count = {'wf': wf, 'token_count': token_count, 'word_count': word_count, 'doc_count': doc_count}\n",
    "    \n",
    "    with open(path_data+\"output/nlp_pipeline/word_count/\"+journal+'.json', 'w', encoding=\"utf-8\") as outfile:\n",
    "        json.dump(journal_count, outfile, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4869944.json\n",
      "Processing 6727476.json\n",
      "Processing 2829132.json\n",
      "Processing 2644300.json\n",
      "Processing 2827798.json\n",
      "Processing 3476254.json\n",
      "Processing 9607226.json\n",
      "Processing 177657.json\n",
      "Processing 6492308.json\n",
      "Processing 9051331.json\n",
      "Processing 9768304.json\n",
      "Processing 2549643.json\n",
      "Processing 4895413.json\n",
      "Processing 8553624.json\n",
      "Processing 4889892.json\n",
      "Processing 4896751.json\n",
      "Processing 2304627.json\n",
      "Processing 9215017.json\n",
      "Processing 4900572.json\n",
      "Processing 9583346.json\n",
      "Processing 9588641.json\n",
      "Processing 2431292.json\n",
      "Processing 9556011.json\n",
      "Processing 4885029.json\n",
      "Processing 2825247.json\n",
      "Processing 1304829.json\n",
      "Processing 2625941.json\n",
      "Processing 6492437.json\n",
      "Processing 2744856.json\n",
      "Processing 2566751.json\n",
      "Processing 4661555.json\n",
      "Processing 2621806.json\n",
      "Processing 2709933.json\n",
      "Processing 2277379.json\n",
      "Processing 7166791.json\n",
      "Processing 9643684.json\n",
      "Processing 2254995.json\n",
      "Processing 2254914.json\n",
      "Processing 6492337.json\n",
      "Processing 2425321.json\n",
      "Processing 4884143.json\n",
      "Processing 8823924.json\n",
      "Processing 5282534.json\n",
      "Processing 6492429.json\n",
      "Processing 9230935.json\n",
      "Processing 4908657.json\n",
      "Processing 4861829.json\n",
      "Processing 3133276.json\n",
      "Processing 2609281.json\n",
      "Processing 2266000.json\n",
      "Processing 3983568.json\n",
      "Processing 4890378.json\n",
      "Processing 8366961.json\n",
      "Processing 700673.json\n",
      "Processing 9530728.json\n",
      "Processing 2572068.json\n",
      "Processing 2708691.json\n",
      "Processing 3495278.json\n",
      "Processing 4904101.json\n",
      "Processing 7507437.json\n",
      "Processing 4921092.json\n",
      "Processing 3053752.json\n",
      "Processing 9643689.json\n",
      "Processing 9643701.json\n",
      "Processing 2828641.json\n",
      "Processing 4782723.json\n",
      "Processing 6492321.json\n",
      "Processing 2276426.json\n",
      "Processing 9805439.json\n",
      "Processing 9805360.json\n",
      "Processing 3980048.json\n",
      "Processing 3224737.json\n",
      "Processing 3776398.json\n",
      "Processing 4908862.json\n",
      "Processing 9607246.json\n",
      "Processing 2929020.json\n",
      "Processing 3970005.json\n",
      "Processing 4781937.json\n",
      "Processing 6485886.json\n",
      "Processing 4874912.json\n",
      "Processing 9626633.json\n",
      "Processing 2416673.json\n",
      "Processing 6682508.json\n",
      "Processing 2542917.json\n",
      "Processing 3020846.json\n",
      "Processing 2045206.json\n",
      "Processing 6492408.json\n",
      "Processing 9072829.json\n",
      "Processing 7957787.json\n",
      "Processing 4883069.json\n",
      "Processing 6492344.json\n",
      "Processing 4889559.json\n",
      "Processing 2292929.json\n",
      "Processing 2420797.json\n",
      "Processing 9610652.json\n",
      "Processing 9643693.json\n",
      "Processing 2827066.json\n",
      "Processing 9366335.json\n",
      "Processing 2429839.json\n",
      "Processing 3089693.json\n",
      "Processing 9942709.json\n",
      "Processing 2542348.json\n",
      "Processing 9230933.json\n",
      "Processing 4785731.json\n",
      "Processing 9768535.json\n",
      "Processing 6492385.json\n",
      "Processing 2821022.json\n",
      "Processing 4892693.json\n",
      "Processing 9620162.json\n",
      "Processing 9643705.json\n",
      "Processing 3768355.json\n",
      "Processing 9934493.json\n",
      "Processing 7086666.json\n",
      "Processing 2425679.json\n",
      "Processing 5367336.json\n",
      "Processing 377570.json\n",
      "Processing 4864325.json\n",
      "Processing 2550047.json\n",
      "Processing 4920222.json\n",
      "Processing 2153553.json\n",
      "Processing 9160927.json\n",
      "Processing 9620166.json\n",
      "Processing 8555529.json\n",
      "Processing 3140913.json\n",
      "Processing 9582244.json\n",
      "Processing 9054153.json\n",
      "Processing 6492301.json\n",
      "Processing 8878932.json\n",
      "Processing 4925979.json\n",
      "Processing 2316602.json\n",
      "Processing 3769475.json\n",
      "Processing 7691597.json\n",
      "Processing 9569290.json\n",
      "Processing 8861699.json\n",
      "Processing 2583479.json\n",
      "Processing 9610650.json\n",
      "Processing 3119801.json\n",
      "Processing 2912821.json\n",
      "Processing 3122061.json\n",
      "Processing 2613366.json\n",
      "Processing 3486266.json\n",
      "Processing 2711613.json\n",
      "Processing 2822870.json\n",
      "Processing 9221535.json\n",
      "Processing 2379786.json\n",
      "Processing 4085237.json\n",
      "Processing 2360092.json\n",
      "Processing 8812431.json\n",
      "Processing 9038025.json\n",
      "Processing 9050316.json\n",
      "Processing 7168181.json\n",
      "Processing 4919024.json\n",
      "Processing 3135693.json\n",
      "Processing 4916913.json\n",
      "Processing 2249537.json\n",
      "Processing 2583875.json\n",
      "Processing 2437270.json\n",
      "Processing 2649276.json\n",
      "Processing 2418846.json\n",
      "Processing 9756662.json\n",
      "Processing 9616701.json\n",
      "Processing 2709108.json\n",
      "Processing 2420973.json\n",
      "Processing 4885084.json\n",
      "Processing 5369809.json\n",
      "Processing 2707513.json\n",
      "Processing 9582242.json\n",
      "Processing 4886575.json\n",
      "Processing 2554541.json\n",
      "Processing 4109741.json\n",
      "Processing 9607695.json\n",
      "Processing 2550626.json\n",
      "Processing 4926100.json\n",
      "Processing 4794429.json\n",
      "Processing 2692297.json\n",
      "Processing 2710055.json\n",
      "Processing 3094266.json\n",
      "Processing 4876568.json\n",
      "Processing 2268830.json\n",
      "Processing 3111067.json\n",
      "Processing 2571117.json\n",
      "Processing 4911661.json\n",
      "Processing 3129675.json\n",
      "Processing 537862.json\n",
      "Processing 2378030.json\n",
      "Processing 7506414.json\n",
      "Processing 9620169.json\n",
      "Processing 3139318.json\n",
      "Processing 3537599.json\n",
      "Processing 3133765.json\n",
      "Processing 2430890.json\n",
      "Processing 2823768.json\n",
      "Processing 9052070.json\n",
      "Processing 2969091.json\n",
      "Processing 6682492.json\n",
      "Processing 8620046.json\n",
      "Processing 2446951.json\n",
      "Processing 7411685.json\n",
      "Processing 8295971.json\n",
      "Processing 4903180.json\n",
      "Processing 6492379.json\n",
      "Processing 3315709.json\n",
      "Processing 8823644.json\n",
      "Processing 10638461.json\n",
      "Processing 4911569.json\n",
      "Processing 6492329.json\n",
      "Processing 4804947.json\n",
      "Processing 8798649.json\n",
      "Processing 8263477.json\n",
      "Processing 3062972.json\n",
      "Processing 3497353.json\n",
      "Processing 5959619.json\n",
      "Processing 6492456.json\n",
      "Processing 9569929.json\n",
      "Processing 2641551.json\n",
      "Processing 2708078.json\n",
      "Processing 2969669.json\n",
      "Processing 2551369.json\n",
      "Processing 2727810.json\n",
      "Processing 52596.json\n",
      "Processing 3101111.json\n",
      "Processing 2651273.json\n",
      "Processing 4889117.json\n",
      "Processing 9230930.json\n",
      "Processing 10112841.json\n",
      "Processing 9050333.json\n",
      "Processing 3947615.json\n",
      "Processing 2895450.json\n",
      "Processing 9047414.json\n",
      "Processing 5438908.json\n",
      "Processing 9643697.json\n",
      "Processing 2629891.json\n",
      "Processing 8495715.json\n",
      "Processing 4872516.json\n",
      "Processing 9805370.json\n",
      "Processing 4896353.json\n",
      "Processing 6467833.json\n",
      "Processing 6465881.json\n",
      "Processing 4926451.json\n",
      "Processing 4807565.json\n",
      "Processing 9539926.json\n",
      "Processing 2566634.json\n",
      "Processing 3504366.json\n",
      "Processing 10555104.json\n",
      "Processing 4795427.json\n",
      "Processing 10279732.json\n",
      "Processing 10855476.json\n",
      "Processing 9160972.json\n",
      "Processing 9759310.json\n",
      "Processing 7413542.json\n",
      "Processing 2720904.json\n",
      "Processing 2638044.json\n",
      "Processing 9498581.json\n",
      "Processing 1112869.json\n",
      "Processing 2273546.json\n",
      "Processing 4086896.json\n",
      "Processing 9616703.json\n",
      "Processing 2432763.json\n",
      "Processing 6492417.json\n",
      "Processing 2424658.json\n",
      "Processing 9620164.json\n",
      "Processing 4884546.json\n",
      "Processing 9643703.json\n",
      "Processing 2580773.json\n",
      "Processing 9643691.json\n",
      "Processing 2577043.json\n",
      "Processing 2642950.json\n",
      "Processing 4862473.json\n",
      "Processing 10622931.json\n",
      "Processing 2650397.json\n",
      "Processing 3771019.json\n",
      "Processing 8245601.json\n",
      "Processing 3092672.json\n",
      "Processing 7242850.json\n",
      "Processing 1099854.json\n",
      "Processing 9643678.json\n",
      "Processing 8003959.json\n",
      "Processing 3126481.json\n",
      "Processing 4794838.json\n",
      "Processing 7938572.json\n",
      "Processing 4903956.json\n",
      "Processing 6492351.json\n",
      "Processing 9643687.json\n",
      "Processing 9582265.json\n",
      "Processing 9038125.json\n",
      "Processing 10279739.json\n",
      "Processing 4917681.json\n",
      "Processing 649716.json\n",
      "Processing 9572329.json\n",
      "Processing 9610648.json\n",
      "Processing 9449368.json\n",
      "Processing 3019627.json\n",
      "Processing 9643699.json\n",
      "Processing 2417805.json\n",
      "Processing 2979076.json\n",
      "Processing 2908689.json\n",
      "Processing 9626648.json\n",
      "Processing 6492399.json\n",
      "Processing 4789469.json\n",
      "Processing 7083615.json\n",
      "Processing 4891256.json\n",
      "Processing 9643695.json\n",
      "Processing 2822530.json\n",
      "Processing 2932754.json\n",
      "Processing 6727475.json\n",
      "Processing 3138070.json\n",
      "Processing 2259275.json\n",
      "Processing 2438141.json\n",
      "Processing 4899998.json\n",
      "Processing 9620171.json\n"
     ]
    }
   ],
   "source": [
    "# compute overall word count, word frequency, token count\n",
    "glob_wf = {\"wf\": {}, \"tc\": 0, \"wc\": 0, \"dc\": 0}\n",
    "\n",
    "for j in os.listdir(path_data+\"output/nlp_pipeline/word_count/\"):\n",
    "    \n",
    "    if not j.startswith('.'):\n",
    "    \n",
    "        print(\"Processing\", j)\n",
    "    \n",
    "        curr_j = json.load(open(path_data+\"output/nlp_pipeline/word_count/\"+j, \"r\", encoding=\"utf-8\"))\n",
    "    \n",
    "        glob_wf['tc'] += curr_j['token_count']\n",
    "        glob_wf['wc'] += curr_j['word_count']\n",
    "        glob_wf['dc'] += curr_j['doc_count']\n",
    "    \n",
    "        for word, count in curr_j['wf'].items():\n",
    "        \n",
    "            if word in glob_wf['wf']:\n",
    "                glob_wf['wf'][word] += count\n",
    "            else:\n",
    "                glob_wf['wf'][word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count: 385829580\n",
      "Total token count: 801381455\n",
      "Total document count: 856042\n",
      "Size of vocabulary: 32797884\n"
     ]
    }
   ],
   "source": [
    "print(\"Total word count: {}\".format(glob_wf['wc']))\n",
    "print(\"Total token count: {}\".format(glob_wf['tc']))\n",
    "print(\"Total document count: {}\".format(glob_wf['dc']))\n",
    "print(\"Size of vocabulary: {}\".format(len(glob_wf['wf'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
