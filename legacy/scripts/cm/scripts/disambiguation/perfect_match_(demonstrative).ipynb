{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given string (mention) form text, we assign the string to the wiki page (entity) whose name perfectly matches\n",
    "# of course this is nothing but a demonstrative example\n",
    "# input: list of candidates from each text\n",
    "# output: mention-entity pair\n",
    "\n",
    "import os, json, pprint, pickle\n",
    "from urllib.parse import unquote\n",
    "root = '/data/cm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pickle.load(open(root+'output/candidate_selection/matched_wiki_from_NER.pickle', 'rb'))\n",
    "# candidate strings from the documents (extracted from NER) that we want to link to Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonness = pickle.load(open(root+'data/wiki/de/commonness.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hafenstadt%20Haifa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e7cfb88e3dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommonness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hafenstadt%20Haifa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Hafenstadt%20Haifa'"
     ]
    }
   ],
   "source": [
    "commonness['Hafenstadt%20Haifa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 159,\n",
      " 'e': 164,\n",
      " 'entities': {'ATP%20Challenger%20Tunis',\n",
      "              'Erzbistum%20Tunis',\n",
      "              'Flughafen%20Tunis',\n",
      "              'Geschichte%20Tunesiens%23Osmanen%20%281574%20bis%201790%20bzw.%201881%29',\n",
      "              'Gouvernement%20Tunis',\n",
      "              'Grand%20Prix%20de%20Tunisie',\n",
      "              'Gro%C3%9Fer%20Preis%20von%20Tunesien',\n",
      "              'Liste%20der%20Beys%20von%20Tunis',\n",
      "              'Regentschaft%20Tunis',\n",
      "              'Stadion%20des%207.%20November',\n",
      "              'Tunesien',\n",
      "              'Tunesienfeldzug',\n",
      "              'Tunis',\n",
      "              'Tunis%20%28Fautmolo%29',\n",
      "              'Tunis%20%28Gouvernorat%29',\n",
      "              'Tunis%20Open%202009',\n",
      "              'Tunis%20Open%202010%23Doppel',\n",
      "              'Tunis%23Geschichte',\n",
      "              'Tunisfeldzug'},\n",
      " 'text': 'Tunis'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(candidates['9620162']['9633717_9625984__511_9625989'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9620162\n",
      "Processing 3139318\n",
      "Processing 2566634\n"
     ]
    }
   ],
   "source": [
    "matches = {k: {} for k in candidates.keys()}\n",
    "for journal, pages in candidates.items():\n",
    "    print('Processing', journal)\n",
    "    \n",
    "    for page, entries in pages.items():\n",
    "        \n",
    "        if page not in matches[journal].keys():\n",
    "            matches[journal][page] = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            target = entry['text'] # string from document to disambiguate\n",
    "            unquoted_entities = [unquote(e) for e in entry['entities']]\n",
    "            # compute commonness for each candidate entities\n",
    "            local_comm = []\n",
    "            for e in entry['entities']:\n",
    "                try:\n",
    "                    local_comm.append((e, commonness[e][target]))\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            \n",
    "            local_comm = sorted(local_comm, key=lambda x:x[1], reverse=True)\n",
    "            #print(target, local_comm[:4])\n",
    "            #print()\n",
    "            \n",
    "            # assign the entity with the highest commonness for that mention\n",
    "            if local_comm != []:\n",
    "                \n",
    "                match = {\n",
    "                    'text': entry['text'],\n",
    "                    'b': entry['b'],\n",
    "                    'e': entry['e'],\n",
    "                    'match': 'https://de.wikipedia.org/wiki/'+local_comm[0][0]\n",
    "                }\n",
    "                matches[journal][page].append(match)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "werden). III Am 15. September gibt der Protestant Theodor Heuss sein seit 10 Jahren hervorragend geführtes Bunlde\n",
      "Theodor Heuss\n",
      "https://de.wikipedia.org/wiki/Theodor%20Heuss\n"
     ]
    }
   ],
   "source": [
    "# provide some examples of the entity in context\n",
    "# 3139318 3133277_3133281__177_3133480 81 92 Paul Bekker\n",
    "# 3139318 3133277_3133281__180_3133483 481 489 Bayreuth\n",
    "# 9620162 9632912_9625712__234_9625713 5288 5301 Theodor Heuss\n",
    "# 9620162 9632912_9625712__234_9625713 5408 5422 Heinrich Lübke\n",
    "\n",
    "journal = '9620162'\n",
    "page = '9632912_9625712__234_9625713'\n",
    "b = int('5288')\n",
    "e = int('5301')\n",
    "url = 'https://de.wikipedia.org/wiki/Theodor%20Heuss'\n",
    "\n",
    "text = open(root+'data/pages/'+journal+'/'+page+'.txt', 'r', encoding='utf-8').read()\n",
    "entity = text[b:e]\n",
    "text_span = text[b-50:e+50]\n",
    "print(text_span)\n",
    "print(entity)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found mention *** jüdischen *** in text:\n",
      "\n",
      "lichen, Inhalt seines Werkes wird. Friedlaender betonte überzeugend den starken jüdischen Kern im Wesen des deutschen Literaten Lion Feuchtwanger, mit dessen Tod einer d\n",
      "\n",
      "Begin: 10262 End: 10271\n",
      "url: https://de.wikipedia.org/wiki/Judentum\n"
     ]
    }
   ],
   "source": [
    "# show random matches with text span\n",
    "import random\n",
    "r = random.randint(0, 18142)\n",
    "#print(r)\n",
    "\n",
    "i = 0\n",
    "for journal, pages in matches.items():\n",
    "    for page, values in pages.items():\n",
    "        for match in values:\n",
    "            i += 1\n",
    "            if i == r:\n",
    "                text = open(root+'data/pages/'+journal+'/'+page+'.txt', 'r', encoding='utf-8').read()\n",
    "                b = int(match['b'])\n",
    "                e = int(match['e'])\n",
    "                url = match['match']\n",
    "                text_span = text[b-80:e+80]\n",
    "                entity_name = match['text']\n",
    "                print('Found mention ***', entity_name, '*** in text:')\n",
    "                print()\n",
    "                print(text_span)\n",
    "                print()\n",
    "                print('Begin:', b, 'End:', e)\n",
    "                print('url:', url)\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
