{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pprint, csv, pickle, elasticsearch, time, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 entity name-uri mapping\n",
    "name_to_uri = json.load(open('/home/rovera/cm/scripts/cooccurrence/output/name_to_uri.json', 'r', encoding=\"utf-8\"))\n",
    "uri_to_name = json.load(open('/home/rovera/cm/scripts/cooccurrence/output/uri_to_name.json', 'r', encoding=\"utf-8\"))\n",
    "# 2 entity pages inverted index\n",
    "ep_inv_index = pickle.load(open('/home/rovera/jl/scripts/entity_pages/ep/runs/run_0/ep_inv_index.pickle', 'rb'))\n",
    "# 3 occurrence by journal\n",
    "occurrence_by_journal = pickle.load(open('/home/rovera/cm/scripts/cooccurrence/output/occ_by_journal_detail.pickle', 'rb'))\n",
    "# 4 related entities\n",
    "entity_correlation = pickle.load(open('/home/rovera/cm/scripts/cooccurrence/output/entity_correlation.pickle', 'rb'))\n",
    "# 5 data types \n",
    "classified_entities = json.load(open('/home/rovera/cm/scripts/jl_linking/classified_entities.json', 'r', encoding=\"utf-8\"))\n",
    "# 6 TAGME mentions\n",
    "#cm_entities = pickle.load(open(\"/home/rovera/cm/scripts/cooccurrence/cm_tagme_resource_reference_data_05_03.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3296\n",
      "chunk 1 3296\n",
      "chunk 2 3296\n",
      "chunk 3 3296\n",
      "chunk 4 3296\n",
      "chunk 5 3296\n",
      "chunk 6 3296\n",
      "chunk 7 3296\n",
      "chunk 8 3296\n",
      "chunk 9 3296\n",
      "chunk 10 3296\n",
      "chunk 11 3296\n",
      "chunk 12 3296\n",
      "chunk 13 3296\n",
      "chunk 14 3296\n",
      "chunk 15 3296\n",
      "chunk 16 3296\n",
      "chunk 17 3296\n",
      "chunk 18 3296\n",
      "chunk 19 3296\n",
      "chunk 20 3296\n",
      "chunk 21 3296\n",
      "chunk 22 3296\n",
      "chunk 23 3296\n",
      "chunk 24 3296\n",
      "chunk 25 3296\n",
      "chunk 26 3296\n",
      "chunk 27 3296\n",
      "chunk 28 3296\n",
      "chunk 29 3296\n",
      "chunk 30 54\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "i,j,chunk = 0,0,0\n",
    "for name, uri in name_to_uri.items():\n",
    "    i += 1\n",
    "    j += 1\n",
    "    occs_by_journal = []\n",
    "    for journal_info, mentions in occurrence_by_journal[uri].items():\n",
    "        journal_mentions = {'j_name': journal_info[1],\n",
    "                                'j_id': journal_info[0],\n",
    "                                'first': mentions['first'],\n",
    "                                'last': mentions['last'],\n",
    "                               'mentions': mentions['data']\n",
    "                               }\n",
    "        occs_by_journal.append(journal_mentions)\n",
    "\n",
    "\n",
    "    occs_by_journal = sorted(occs_by_journal, key=lambda x:len(x['mentions']), reverse=True)\n",
    "    related_entities = sorted([[res_uri, uri_to_name[res_uri], score] for res_uri, score in entity_correlation[uri].items()], key=lambda x:x[2], reverse=True)\n",
    "\n",
    "    # add entity type information to related entities\n",
    "    for rel_ent in related_entities:\n",
    "        ent_type = classified_entities[rel_ent[1].replace(' ', '_')]\n",
    "        rel_ent.append(ent_type)\n",
    "\n",
    "\n",
    "    label_name = name.replace(' ', '_')\n",
    "    e_type = classified_entities[label_name]\n",
    "    if len(e_type) == 0:\n",
    "        e_type = \"OTH\"\n",
    "\n",
    "\n",
    "    header = {'_id': str(j), '_index': 'cm_entities'}\n",
    "    body = {'name': name,\n",
    "            'e_type': e_type,\n",
    "            'journal_occs': occs_by_journal,\n",
    "            'related_entities': related_entities,\n",
    "            'ep': ''\n",
    "           }\n",
    "    # to be fixed: not all entity pages exist!\n",
    "    if uri in ep_inv_index:\n",
    "        body['ep'] = ep_inv_index[uri]\n",
    "\n",
    "\n",
    "    data.append(json.dumps({\"index\": header}, ensure_ascii=False))\n",
    "    data.append(json.dumps(body, ensure_ascii=False))\n",
    "\n",
    "    if i == 200:\n",
    "        print(sys.getsizeof(data))\n",
    "        with open('/data/cm/output/temp_journals_detail/chunk_'+str(chunk)+'.json', \"w\", encoding=\"utf-8\") as write_file:\n",
    "            write_file.write(\"\\n\".join(data))\n",
    "        data = []\n",
    "        i = 0\n",
    "        chunk += 1\n",
    "        print(\"chunk\", chunk, end=\" \")\n",
    "\n",
    "    \n",
    "with open('/data/cm/output/temp_journals_detail/chunk_'+str(chunk)+'.json', \"w\", encoding=\"utf-8\") as write_file:\n",
    "    write_file.write(\"\\n\".join(data))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define mappings\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        'name': {'type': 'text'},\n",
    "        'ep': {'type': 'text'},\n",
    "        'e_type': {'type': 'text'},\n",
    "        'journal_occs': {'type': 'nested',\n",
    "                        'properties': {\n",
    "                            'j_name': {'type': 'text'},\n",
    "                            'j_id': {'type': 'text'},\n",
    "                            'first': {'type': 'integer'},\n",
    "                            'last': {'type': 'integer'},\n",
    "                            'mentions': {\n",
    "                                'type': 'nested',\n",
    "                                'properties': {\n",
    "                                    'p_id': {'type': 'text'},\n",
    "                                    'spot': {'type': 'text'},\n",
    "                                    'start': {'type': 'integer'},\n",
    "                                    'end': {'type': 'integer'},\n",
    "                                    'p_link': {'type': 'text'},\n",
    "                                    'date': {'type': 'text'}\n",
    "                                } \n",
    "                            }\n",
    "                        }\n",
    "                        },\n",
    "        'related_entities': {'type': 'text'}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'cm_entities'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ES instance\n",
    "es = elasticsearch.Elasticsearch()\n",
    "ic = elasticsearch.client.IndicesClient(es)\n",
    "if ic.exists('cm_entities'):\n",
    "    ic.delete('cm_entities')\n",
    "ic.create(index='cm_entities', body={'settings': {\"index.mapping.nested_objects.limit\": 500000}, 'mappings': mappings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_30.json\n",
      "chunk_12.json\n",
      "chunk_2.json\n",
      "chunk_28.json\n",
      "chunk_22.json\n",
      "chunk_14.json\n",
      "chunk_18.json\n",
      "chunk_25.json\n",
      "chunk_5.json\n",
      "chunk_6.json\n",
      "chunk_4.json\n",
      "chunk_24.json\n",
      "chunk_13.json\n",
      "chunk_16.json\n",
      "chunk_21.json\n",
      "chunk_29.json\n",
      "chunk_11.json\n",
      "chunk_0.json\n",
      "chunk_10.json\n",
      "chunk_1.json\n",
      "chunk_17.json\n",
      "chunk_20.json\n",
      "chunk_8.json\n",
      "chunk_3.json\n",
      "chunk_26.json\n",
      "chunk_7.json\n",
      "chunk_19.json\n",
      "chunk_23.json\n",
      "chunk_27.json\n",
      "chunk_9.json\n",
      "chunk_15.json\n"
     ]
    }
   ],
   "source": [
    "# Indexing data\n",
    "for file in os.listdir('/data/cm/output/temp_journals_detail/'):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        print(file)\n",
    "\n",
    "        data = open('/data/cm/output/temp_journals_detail/'+file, \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "        es_index = es.bulk(data, request_timeout=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search took 3.36\n"
     ]
    }
   ],
   "source": [
    "# test query\n",
    "es = elasticsearch.Elasticsearch()\n",
    "start = time.time()\n",
    "res = es.search(index='cm_entities', body={'size': 1, \"query\": {\"match_phrase\": {'name': 'Israel'}}})\n",
    "end = time.time()\n",
    "print(\"Search took\", round(end-start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits: 30\n",
      "Israel\n"
     ]
    }
   ],
   "source": [
    "print(\"Total hits:\", res['hits']['total']['value'])\n",
    "for doc in res['hits']['hits']:\n",
    "    print(doc['_source']['name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
