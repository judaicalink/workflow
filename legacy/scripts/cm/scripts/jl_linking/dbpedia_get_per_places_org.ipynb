{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pprint, json, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 6054 labels, 83 of which have still to be processed.\n"
     ]
    }
   ],
   "source": [
    "resource_ids = json.load(open('/home/rovera/cm/scripts/cooccurrence/output/uri_to_name.json', 'r', encoding=\"utf-8\"))\n",
    "output = json.load(open('entity_type_data.json', 'r', encoding=\"utf-8\"))\n",
    "to_do_count = len([v for v in output.values() if len(v) == 0])\n",
    "print(\"The dataset consists of {} labels, {} of which have still to be processed.\".format(len(output), to_do_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franz_Mehring\n"
     ]
    }
   ],
   "source": [
    "for o in output:\n",
    "    print(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haman TODO 0\n",
      "Jesaja TODO 1\n",
      "Jeremia TODO 1\n",
      "Chasan_(Kantor) TODO 0\n",
      "Ezechiel TODO 1\n",
      "Kaleb TODO 1\n",
      "Balak_(Person) TODO 1\n",
      "Joab TODO 1\n",
      "Mordechai TODO 0\n",
      "Ijob TODO 1\n",
      "Ebed-Melech TODO 0\n",
      "Haguenau TODO 0\n",
      "Julien_Benda TODO 0\n",
      "Shanghai TODO 1\n",
      "Jesus_Christus TODO 1\n",
      "Tunis TODO 1\n",
      "Amora_(Judentum) TODO 0\n",
      "Wilhelm_Gesenius TODO 0\n",
      "Schtadlan TODO 0\n",
      "Vorarlberg TODO 1\n",
      "Mohel TODO 0\n",
      "Titus_Tobler TODO 0\n",
      "August_WÃ¼nsche TODO 0\n",
      "Josef_Albo TODO 0\n",
      "Hawila TODO 0\n",
      "Josua,_der_Sohn_Nuns TODO 0\n",
      "Urija TODO 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "target_prefixes = ('http://xmlns.com/foaf/0.1',\n",
    "                        'http://dbpedia.org/ontology',\n",
    "                        'http://schema.org'\n",
    "                       )\n",
    "for entity in output.keys():\n",
    "    #print(entity, end=\" \")\n",
    "    if len(output[entity]) == 0:\n",
    "        print(entity, \"TODO\", end=\" \")\n",
    "        resource = 'http://de.dbpedia.org/resource/'+entity\n",
    "        # perform query\n",
    "        sparql = SPARQLWrapper(\"http://de.dbpedia.org/sparql\")\n",
    "        sparql.setQuery(\"\"\"\n",
    "            SELECT DISTINCT ?entity ?entitytype\n",
    "            WHERE {\n",
    "                ?entity a ?entitytype .\n",
    "                FILTER (?entity = <\"\"\"+resource+\"\"\">)\n",
    "                }\n",
    "\n",
    "        \"\"\")\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "        print(len(results['results']['bindings']))\n",
    "        for res in results['results']['bindings']:\n",
    "            entitytype = res['entitytype']['value']\n",
    "            prefix = \"/\".join(entitytype.split('/')[:-1])\n",
    "            #print(prefix)\n",
    "            if prefix in target_prefixes:\n",
    "                output[entity].append(entitytype)\n",
    "        time.sleep(3.0)\n",
    "        i += 1\n",
    "    \n",
    "    #print(\"|\", end=\"\")\n",
    "    if i % 10 == 0:\n",
    "        json.dump(output, open('entity_type_data.json', 'w', encoding=\"utf-8\"), indent=2, ensure_ascii=False)\n",
    "        output = json.load(open('entity_type_data.json', 'r', encoding=\"utf-8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://dbpedia.org/ontology/Place', 'http://dbpedia.org/ontology/Location', 'http://schema.org/Place', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://dbpedia.org/ontology/Settlement']\n"
     ]
    }
   ],
   "source": [
    "print(output['Stadtlengsfeld'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.load(open('entity_type_data.json', 'r', encoding=\"utf-8\"))\n",
    "classified_entities = {k: '' for k in output.keys()}\n",
    "for label, classes in output.items():\n",
    "    for cl in classes:\n",
    "        if cl.endswith('Person'):\n",
    "            classified_entities[label] = 'PER'\n",
    "            break\n",
    "        if cl.endswith('Location') or cl.endswith('Place'):\n",
    "            classified_entities[label] = 'LOC'\n",
    "            break\n",
    "json.dump(classified_entities, open('classified_entities.json', 'w', encoding=\"utf-8\"), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_Ernst\n",
      "Georges_Braque\n",
      "Erwin_Blumenfeld\n"
     ]
    }
   ],
   "source": [
    "for k,v in output.items():\n",
    "    if 'http://schema.org/Painting' in v:\n",
    "        print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
